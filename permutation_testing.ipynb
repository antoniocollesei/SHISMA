{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The iteration has converged at 7-iter:   7%|▋         | 7/100 [00:00<00:00, 163.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 significant subnetworks.\n",
      "Subnetwork with 4980 nodes | Score: 1.00 | p-value: 0.0010\n",
      "Threshold Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy.sparse as sp\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import norm\n",
    "from pyrwr.rwr import RWR\n",
    "\n",
    "def save_graph_to_file(G, file_path):\n",
    "    \"\"\"Save the graph as an edge list file.\"\"\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        for u, v in G.edges():\n",
    "            f.write(f\"{u}\\t{v}\\t1.0\\n\")\n",
    "\n",
    "def get_connected_components(adj_matrix):\n",
    "    \"\"\"Find connected components using sparse matrix operations.\"\"\"\n",
    "    _, labels = sp.csgraph.connected_components(adj_matrix, directed=False)\n",
    "    return labels\n",
    "\n",
    "def compute_subnetwork_scores(adj_matrix, scores):\n",
    "    \"\"\"Compute subnetwork scores using connected components.\"\"\"\n",
    "    labels = get_connected_components(adj_matrix)\n",
    "    unique_labels, sums = np.unique(labels, return_counts=False), np.zeros(labels.max() + 1)\n",
    "\n",
    "    np.add.at(sums, labels, scores)\n",
    "    return sums, labels\n",
    "\n",
    "def permuted_max_score(adj_matrix, scores):\n",
    "    \"\"\"Shuffle scores and return the max subnetwork score.\"\"\"\n",
    "    random.shuffle(scores)\n",
    "    return max(compute_subnetwork_scores(adj_matrix, scores)[0])\n",
    "\n",
    "def generate_null_distribution(adj_matrix, scores, n_permutations=1000, n_jobs=-1):\n",
    "    \"\"\"Parallelized null distribution computation.\"\"\"\n",
    "    return Parallel(n_jobs=n_jobs)(\n",
    "        delayed(permuted_max_score)(adj_matrix, scores.copy()) for _ in range(n_permutations)\n",
    "    )\n",
    "\n",
    "def compute_p_values(actual_scores, null_distribution):\n",
    "    \"\"\"Compute p-values by comparing actual subnetwork scores to the null distribution.\"\"\"\n",
    "    null_distribution = np.array(null_distribution)\n",
    "    p_values = [(np.sum(null_distribution >= score) + 1) / (len(null_distribution) + 1) for score in actual_scores]\n",
    "    return np.array(p_values)\n",
    "\n",
    "def compute_rwr_scores(graph_file, seed_scores, restart_prob=0.85):\n",
    "    \"\"\"Compute RWR-based node scores using pyrwr.RWR.\"\"\"\n",
    "    rwr = RWR()\n",
    "    rwr.read_graph(graph_file, graph_type=\"undirected\")\n",
    "    \n",
    "    # Use only one seed node as per pyrwr's RWR function\n",
    "    seed_node = max(seed_scores, key=seed_scores.get)  # Select the highest-weight seed node\n",
    "    rwr_scores = rwr.compute(seed_node, c=restart_prob)\n",
    "    return np.array(rwr_scores)\n",
    "\n",
    "def find_significant_subnetworks(graph_file, seed_scores, adj_matrix, nodes, alpha=0.05, n_permutations=1000):\n",
    "    \"\"\"Find significant subnetworks using RWR-based scores.\"\"\"\n",
    "    scores = compute_rwr_scores(graph_file, seed_scores)\n",
    "    actual_scores, labels = compute_subnetwork_scores(adj_matrix, scores)\n",
    "    null_distribution = generate_null_distribution(adj_matrix, scores, n_permutations)\n",
    "    p_values = compute_p_values(actual_scores, null_distribution)\n",
    "    threshold = np.percentile(null_distribution, 100 * (1 - alpha))\n",
    "\n",
    "    significant_subnetworks = []\n",
    "    for i, (score, p_val) in enumerate(zip(actual_scores, p_values)):\n",
    "        if score > threshold:\n",
    "            significant_nodes = [nodes[j] for j in range(len(nodes)) if labels[j] == i]\n",
    "            significant_subnetworks.append({\"nodes\": significant_nodes, \"score\": score, \"p_value\": p_val})\n",
    "\n",
    "    return significant_subnetworks, threshold\n",
    "\n",
    "# Example Usage\n",
    "graph_file = \"graph_edges.tsv\"\n",
    "G = nx.erdos_renyi_graph(5000, 0.001)\n",
    "save_graph_to_file(G, graph_file)\n",
    "\n",
    "nodes = list(G.nodes())\n",
    "node_index = {node: i for i, node in enumerate(nodes)}\n",
    "\n",
    "deg_matrix = sp.diags([G.degree(n) for n in nodes])\n",
    "adj_matrix = nx.to_scipy_sparse_array(G, nodelist=nodes, format='csr')\n",
    "\n",
    "seed_scores = {random.choice(nodes): random.uniform(0, 1) for _ in range(10)}\n",
    "\n",
    "significant_subnetworks, threshold = find_significant_subnetworks(graph_file, seed_scores, adj_matrix, nodes)\n",
    "print(f\"Found {len(significant_subnetworks)} significant subnetworks.\")\n",
    "for sub in significant_subnetworks[:5]:\n",
    "    print(f\"Subnetwork with {len(sub['nodes'])} nodes | Score: {sub['score']:.2f} | p-value: {sub['p_value']:.4f}\")\n",
    "\n",
    "print(f\"Threshold Score: {threshold:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The iteration has converged at 7-iter:   7%|▋         | 7/100 [00:00<00:00, 760.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 significant subnetworks.\n",
      "Subnetwork with 4970 nodes | Score: 1.00 | p-value: 0.0290\n",
      "Threshold Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy.sparse as sp\n",
    "from joblib import Parallel, delayed\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from pyrwr.rwr import RWR\n",
    "\n",
    "def save_graph_to_file(G, file_path):\n",
    "    \"\"\"Save the graph as an edge list file.\"\"\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        for u, v in G.edges():\n",
    "            f.write(f\"{u}\\t{v}\\t1.0\\n\")\n",
    "\n",
    "def get_connected_components(adj_matrix):\n",
    "    \"\"\"Find connected components using sparse matrix operations.\"\"\"\n",
    "    _, labels = sp.csgraph.connected_components(adj_matrix, directed=False)\n",
    "    return labels\n",
    "\n",
    "def compute_subnetwork_scores(adj_matrix, scores):\n",
    "    \"\"\"Compute subnetwork scores using connected components.\"\"\"\n",
    "    labels = get_connected_components(adj_matrix)\n",
    "    unique_labels, sums = np.unique(labels, return_counts=False), np.zeros(labels.max() + 1)\n",
    "\n",
    "    np.add.at(sums, labels, scores)\n",
    "    return sums, labels\n",
    "\n",
    "def permuted_max_score(adj_matrix, scores):\n",
    "    \"\"\"Shuffle scores and return the max subnetwork score.\"\"\"\n",
    "    random.shuffle(scores)\n",
    "    return max(compute_subnetwork_scores(adj_matrix, scores)[0])\n",
    "\n",
    "def generate_null_distribution(adj_matrix, scores, n_permutations=1000, n_jobs=-1):\n",
    "    \"\"\"Parallelized null distribution computation.\"\"\"\n",
    "    return Parallel(n_jobs=n_jobs)(\n",
    "        delayed(permuted_max_score)(adj_matrix, scores.copy()) for _ in range(n_permutations)\n",
    "    )\n",
    "\n",
    "def compute_p_values(actual_scores, null_distribution):\n",
    "    \"\"\"Compute p-values and apply multiple testing correction.\"\"\"\n",
    "    null_distribution = np.array(null_distribution)\n",
    "    p_values = [(np.sum(null_distribution >= score) + 1) / (len(null_distribution) + 1) for score in actual_scores]\n",
    "    p_values = np.array(p_values)\n",
    "    corrected_p_values = multipletests(p_values, method='fdr_bh')[1]  # Benjamini-Hochberg correction\n",
    "    return corrected_p_values\n",
    "\n",
    "def compute_rwr_scores(graph_file, seed_scores, restart_prob=0.85):\n",
    "    \"\"\"Compute RWR-based node scores using pyrwr.RWR.\"\"\"\n",
    "    rwr = RWR()\n",
    "    rwr.read_graph(graph_file, graph_type=\"undirected\")\n",
    "    \n",
    "    # Use only one seed node as per pyrwr's RWR function\n",
    "    seed_node = max(seed_scores, key=seed_scores.get)  # Select the highest-weight seed node\n",
    "    rwr_scores = rwr.compute(seed_node, c=restart_prob)\n",
    "    return np.array(rwr_scores)\n",
    "\n",
    "def find_significant_subnetworks(graph_file, seed_scores, adj_matrix, nodes, alpha=0.05, n_permutations=1000):\n",
    "    \"\"\"Find significant subnetworks using RWR-based scores.\"\"\"\n",
    "    scores = compute_rwr_scores(graph_file, seed_scores)\n",
    "    actual_scores, labels = compute_subnetwork_scores(adj_matrix, scores)\n",
    "    null_distribution = generate_null_distribution(adj_matrix, scores, n_permutations)\n",
    "    p_values = compute_p_values(actual_scores, null_distribution)\n",
    "    threshold = np.percentile(null_distribution, 100 * (1 - alpha))\n",
    "\n",
    "    significant_subnetworks = []\n",
    "    for i, (score, p_val) in enumerate(zip(actual_scores, p_values)):\n",
    "        if p_val < alpha:\n",
    "            significant_nodes = [nodes[j] for j in range(len(nodes)) if labels[j] == i]\n",
    "            significant_subnetworks.append({\"nodes\": significant_nodes, \"score\": score, \"p_value\": p_val})\n",
    "\n",
    "    return significant_subnetworks, threshold\n",
    "\n",
    "# Example Usage\n",
    "graph_file = \"graph_edges.tsv\"\n",
    "G = nx.erdos_renyi_graph(5000, 0.001)\n",
    "save_graph_to_file(G, graph_file)\n",
    "\n",
    "nodes = list(G.nodes())\n",
    "node_index = {node: i for i, node in enumerate(nodes)}\n",
    "\n",
    "deg_matrix = sp.diags([G.degree(n) for n in nodes])\n",
    "adj_matrix = nx.to_scipy_sparse_array(G, nodelist=nodes, format='csr')\n",
    "\n",
    "seed_scores = {random.choice(nodes): random.uniform(0, 1) for _ in range(10)}\n",
    "\n",
    "significant_subnetworks, threshold = find_significant_subnetworks(graph_file, seed_scores, adj_matrix, nodes)\n",
    "print(f\"Found {len(significant_subnetworks)} significant subnetworks.\")\n",
    "for sub in significant_subnetworks[:5]:\n",
    "    print(f\"Subnetwork with {len(sub['nodes'])} nodes | Score: {sub['score']:.2f} | p-value: {sub['p_value']:.4f}\")\n",
    "\n",
    "print(f\"Threshold Score: {threshold:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genelets_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
